{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boundmixofgaussians import findpeak, compute_sum, compute_grad\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True,precision=6)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from GPAdversarialBound import getallchanges, zeromean_gaussian, getbound, AdversBound, compute_bounds\n",
    "from GPAdversarialBound.logistic import get_logistic_result\n",
    "from GPAdversarialDatasets import getMNISTexample, getbankexample, getcreditexample, getspamexample,getsynthexample\n",
    "\n",
    "# from GPAdversarialBound.test import testing\n",
    "# testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing 3 vs 5\n"
     ]
    }
   ],
   "source": [
    "trainingN = 100\n",
    "testN = 200\n",
    "fullX,Y = getMNISTexample(scalingfactor=4,Ntraining=trainingN+testN,splittype='35') #4\n",
    "keep = np.max(fullX,0)>50 #150\n",
    "X = fullX[:,keep]\n",
    "X=X-np.min(X,0)\n",
    "X=X/np.max(X,0)\n",
    "X = X*1.0\n",
    "Y = Y*1.0\n",
    "Y[Y==0]=-1\n",
    "Xtest = X[trainingN:,:]\n",
    "Ytest = Y[trainingN:,:]\n",
    "Xtrain = X[0:trainingN,:]\n",
    "Ytrain = Y[0:trainingN,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing sparse approximation with basic result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters gp_classification.rbf.variance\n",
      "reconstraining parameters sparse_gp.rbf.variance\n",
      "reconstraining parameters gp_classification.rbf.variance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n",
      "[2.274482]\n",
      "0.6\n",
      "[1.428104]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 4.,\n",
       "        2., 5.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4,\n",
       "        2.6, 2.8, 3. , 3.2, 3.4, 3.6, 3.8]),\n",
       " <a list of 1 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results, _, _, accuracy, abCI = compute_bounds(Xtrain,Ytrain,Xtest,Ytest,1, 4, 1.0, 0.5, 0.0001,2)\n",
    "print(accuracy)\n",
    "print(np.diff(abCI))\n",
    "plt.hist([np.max(res[0]) for res in results],bins=np.arange(0,4,0.2),alpha=0.3)\n",
    "\n",
    "results, _, _, accuracy, abCI = compute_bounds(Xtrain,Ytrain,Xtest,Ytest,1,False, 1.0, 0.5, 0.0001,2)\n",
    "print(accuracy)\n",
    "print(np.diff(abCI))\n",
    "plt.hist([np.max(res[0]) for res in results],bins=np.arange(0,4,0.2),alpha=0.3,histtype='stepfilled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance between the 5th and 95th percentile training points is reported above in [brackets]. Both computations seem to end up above these thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an additional process in which the largest results are recomputed with a tighter bound:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters gp_classification.rbf.variance\n",
      "reconstraining parameters sparse_gp.rbf.variance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6079 --> 1.3344\n",
      "1.3344 2.2882 2.5983\n",
      "2.5983 --> 1.3700\n",
      "1.3344 2.2200 2.5932\n",
      "2.5932 --> 1.3555\n",
      "1.3344 2.1512 2.5909\n",
      "2.5909 --> 1.3451\n",
      "1.3344 2.0820 2.5612\n",
      "2.5612 --> 1.4119\n",
      "1.3344 2.0181 2.5571\n",
      "2.5571 --> 1.5164\n",
      "1.3344 1.9603 2.5452\n",
      "2.5452 --> 1.3643\n",
      "1.3344 1.8947 2.4514\n",
      "2.4514 --> 1.7524\n",
      "1.3344 1.8559 2.4413\n",
      "2.4413 --> 1.3664\n",
      "1.3344 1.7962 2.3977\n",
      "2.3977 --> 1.7143\n",
      "1.3344 1.7582 2.3606\n",
      "0.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 6., 2., 2., 2., 2., 4., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4,\n",
       "        2.6, 2.8, 3. , 3.2, 3.4, 3.6, 3.8]),\n",
       " <a list of 19 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results, _, _, accuracy, abCI = compute_bounds(Xtrain,Ytrain,Xtest,Ytest,1,4, 1.0, 0.5, 0.0001,2,50,2,(7, 10))\n",
    "print(accuracy)\n",
    "plt.hist([np.max(res[0]) for res in results],bins=np.arange(0,4,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.730865]\n"
     ]
    }
   ],
   "source": [
    "print(np.diff(abCI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example all the possible paths considered are now below this threshold, so we know at least two pixels need changing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare with logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C, Score, cumulativelatents[0], cumulativelatents[1], cumulativelatents[2], cumulativelatents[3], cumulativelatents[4], ci, pixelsneeded\n",
      "0.01, 50.00, 0.03, 0.06, 0.08, 0.11, 0.13, 0.10, 3\n",
      "0.01, 50.00, 0.04, 0.07, 0.10, 0.13, 0.15, 0.11, 3\n",
      "0.01, 50.00, 0.05, 0.08, 0.12, 0.16, 0.18, 0.14, 3\n",
      "0.01, 53.00, 0.06, 0.10, 0.15, 0.19, 0.22, 0.16, 3\n",
      "0.01, 57.00, 0.07, 0.12, 0.18, 0.23, 0.27, 0.20, 3\n",
      "0.02, 60.00, 0.08, 0.15, 0.21, 0.27, 0.32, 0.23, 3\n",
      "0.02, 64.00, 0.10, 0.18, 0.25, 0.33, 0.38, 0.27, 3\n",
      "0.03, 62.00, 0.11, 0.21, 0.30, 0.39, 0.45, 0.32, 3\n",
      "0.03, 63.50, 0.13, 0.25, 0.36, 0.46, 0.54, 0.38, 3\n",
      "0.04, 67.00, 0.16, 0.29, 0.42, 0.55, 0.64, 0.44, 3\n",
      "0.05, 68.50, 0.18, 0.35, 0.50, 0.65, 0.75, 0.51, 3\n",
      "0.06, 68.00, 0.21, 0.40, 0.59, 0.76, 0.88, 0.58, 2\n",
      "0.07, 67.50, 0.25, 0.47, 0.68, 0.88, 1.03, 0.67, 2\n",
      "0.09, 68.50, 0.28, 0.55, 0.79, 1.03, 1.20, 0.76, 2\n",
      "0.11, 69.00, 0.32, 0.63, 0.92, 1.18, 1.38, 0.86, 2\n",
      "0.14, 69.00, 0.37, 0.72, 1.05, 1.36, 1.58, 0.96, 2\n",
      "0.17, 69.50, 0.42, 0.82, 1.20, 1.55, 1.81, 1.07, 2\n",
      "0.20, 69.50, 0.47, 0.94, 1.37, 1.76, 2.05, 1.19, 2\n",
      "0.25, 69.00, 0.53, 1.06, 1.55, 1.99, 2.34, 1.31, 2\n",
      "0.30, 69.00, 0.60, 1.19, 1.75, 2.24, 2.65, 1.44, 2\n",
      "0.37, 68.00, 0.67, 1.34, 1.96, 2.51, 2.98, 1.58, 2\n",
      "0.45, 68.50, 0.76, 1.49, 2.19, 2.79, 3.35, 1.74, 2\n",
      "0.55, 68.00, 0.85, 1.66, 2.44, 3.10, 3.74, 1.89, 2\n",
      "0.67, 68.50, 0.94, 1.84, 2.70, 3.44, 4.17, 2.04, 2\n",
      "0.82, 69.50, 1.05, 2.04, 2.98, 3.83, 4.63, 2.21, 2\n",
      "1.00, 69.00, 1.18, 2.25, 3.28, 4.26, 5.12, 2.41, 2\n",
      "1.22, 70.50, 1.31, 2.47, 3.61, 4.72, 5.64, 2.63, 2\n",
      "1.49, 71.00, 1.46, 2.71, 3.97, 5.21, 6.20, 2.86, 2\n",
      "1.82, 71.00, 1.62, 3.03, 4.39, 5.74, 6.80, 3.09, 2\n",
      "2.23, 72.00, 1.79, 3.38, 4.85, 6.31, 7.44, 3.34, 1\n",
      "2.72, 72.00, 1.98, 3.76, 5.34, 6.91, 8.16, 3.58, 1\n",
      "3.32, 72.00, 2.19, 4.17, 5.87, 7.56, 8.94, 3.84, 1\n",
      "4.06, 72.00, 2.41, 4.61, 6.44, 8.25, 9.78, 4.11, 1\n",
      "4.95, 72.00, 2.65, 5.08, 7.05, 8.99, 10.68, 4.40, 1\n",
      "6.05, 72.00, 2.92, 5.59, 7.70, 9.78, 11.65, 4.70, 1\n",
      "7.39, 72.00, 3.20, 6.13, 8.39, 10.63, 12.68, 5.01, 1\n",
      "9.03, 72.50, 3.51, 6.71, 9.13, 11.52, 13.79, 5.32, 1\n",
      "11.02, 72.50, 3.84, 7.34, 9.91, 12.48, 14.98, 5.70, 1\n",
      "13.46, 71.00, 4.21, 8.00, 10.75, 13.50, 16.25, 6.14, 1\n",
      "16.44, 69.50, 4.60, 8.72, 11.74, 14.68, 17.61, 6.57, 1\n",
      "20.09, 69.50, 5.02, 9.48, 12.81, 15.95, 19.07, 7.03, 1\n",
      "24.53, 69.00, 5.49, 10.30, 13.95, 17.31, 20.63, 7.52, 1\n",
      "29.96, 68.00, 5.98, 11.17, 15.18, 18.77, 22.29, 8.04, 1\n",
      "36.60, 68.00, 6.52, 12.10, 16.50, 20.34, 24.08, 8.60, 1\n",
      "44.70, 68.00, 7.10, 13.10, 17.92, 22.01, 25.99, 9.02, 1\n",
      "54.60, 68.00, 7.73, 14.16, 19.43, 23.79, 28.01, 9.40, 1\n",
      "66.69, 67.00, 8.39, 15.28, 21.03, 25.68, 30.16, 10.06, 1\n",
      "81.45, 67.50, 9.09, 16.47, 22.72, 27.67, 32.57, 10.75, 1\n",
      "99.48, 65.50, 9.83, 17.71, 24.49, 29.97, 35.23, 11.48, 1\n",
      "121.51, 64.50, 10.61, 19.01, 26.34, 32.42, 38.01, 12.18, 1\n"
     ]
    }
   ],
   "source": [
    "logres = get_logistic_result(Xtrain,Ytrain,Xtest,Ytest)\n",
    "print(\"C, Score, cumulativelatents[0], cumulativelatents[1], cumulativelatents[2], cumulativelatents[3], cumulativelatents[4], ci, pixelsneeded\")\n",
    "for r in logres:\n",
    "    print(\"%0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %0.2f, %d\" % tuple(r))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
